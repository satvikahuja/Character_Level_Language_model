{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "7389e34a-f506-4167-9785-e283a3a160e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open(\"/Users/satvikahuja13/makemore/names.txt\", 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "b3afa7c7-62e9-4096-83f1-9b950b486714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocab for characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "6eaa161d-b953-4174-a4eb-7314cb53e73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182437, 8]) torch.Size([182437])\n",
      "torch.Size([22781, 8]) torch.Size([22781])\n",
      "torch.Size([22928, 8]) torch.Size([22928])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "8560ecf6-9cde-4968-a286-aaec65480881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "be592232-adfb-465c-81c8-ca167b192b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7337\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "71209129-e7ee-4bf7-8fb2-84b2293baa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "b58b7575-dd39-4012-aafe-88fc291ba012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4052, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "ac426c94-c80c-43f1-9023-99dd3ee58018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]),\n",
       " torch.Size([32, 1]),\n",
       " torch.Size([32, 27]),\n",
       " torch.Size([32, 1]),\n",
       " torch.Size([32, 27]),\n",
       " torch.Size([32, 1]),\n",
       " torch.Size([32, 27]),\n",
       " torch.Size([32, 27]),\n",
       " torch.Size([32, 1]),\n",
       " torch.Size([32, 27]),\n",
       " torch.Size([32, 27]),\n",
       " torch.Size([64, 27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([32, 27]),\n",
       " torch.Size([27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([32, 200]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 1, 64]))"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum.shape, dprobs.shape, dcounts_sum_inv.shape, norm_logits.shape, logit_maxes.shape, logits.shape, dnorm_logits.shape, dlogit_maxes.shape, norm_logits.shape, dcounts.shape,W2.shape, h.shape, dlogits.shape, b2.shape, hpreact.shape, ((torch.tanh(hpreact)*torch.tanh(hpreact))).shape, dhpreact.shape, bnraw.shape, hpreact.shape, bnbias.shape, dbnraw.shape, bnvar_inv.shape, bndiff.shape, dbnraw.shape, dbnraw.squeeze(0).shape, bnvar.shape, dbnvar_inv.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "13e73d0b-b92c-4561-afac-9e07098d6e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " 32)"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bndiff.shape, bnvar_inv.shape, dbnraw.shape, bnmeani.shape, dbnmeani.shape, hprebn.shape, ((1/n)*dbnmeani).shape, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "b90eb9bb-0f0c-418f-a271-518e1537682c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64]), torch.Size([80, 64]), torch.Size([32, 80]))"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.shape, W1.shape, embcat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd75d8-3df3-45ab-8365-b319a7fe784a",
   "metadata": {},
   "source": [
    "# Manually writing Backprop(loss.backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "8d9a00a9-8934-45d4-9ebb-69d0360cda8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "#loss\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = (1.0/probs) *  dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts)* dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = -dnorm_logits.sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1 - (h*h)) * dh\n",
    "dbngain = (dhpreact * bnraw).sum(0, keepdim=True)\n",
    "dbnraw = (dhpreact * bngain)\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbndiff = dbnraw * bnvar_inv\n",
    "dbnvar = (-0.5*(bnvar+1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1/(n-1)*torch.ones_like(bndiff2)) * dbnvar\n",
    "dbndiff += 2*bndiff * dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = -dbndiff.sum(0, keepdim=True)\n",
    "dhprebn += 1.0/n *torch.ones_like(hprebn) *(dbnmeani)\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k, j]\n",
    "        dC[ix] += demb[k,j]\n",
    "\n",
    "# # -----------------\n",
    "# YOUR CODE HERE :)\n",
    "# -----------------\n",
    "#loss\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "e7e185b3-f1bb-4d66-ae46-d91269e1ba2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4051992893218994 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "81149c68-9a76-4ad8-bace-9e80f2f06be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.28642737865448e-09\n"
     ]
    }
   ],
   "source": [
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "62b57a85-d32a-4ff2-9234-497a374a3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = F.softmax(logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "14c09b29-9095-4c9b-9b5d-cf75a5036db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.3970e-09, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "527cddcf-9170-4587-af05-9daad0028afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x136404640>"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "afe104de-9eb6-40f4-b9fc-94bcdc26d0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "3545c266-3494-4c3a-8bd3-c1e4ae6a3148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "f8131da1-12fb-4611-b894-9e090ffa3d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "737c3d8a-6514-4186-8f5c-0124f71b371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22297\n",
      "      0/ 200000: 3.5724\n",
      "  10000/ 200000: 2.0903\n",
      "  20000/ 200000: 1.8816\n",
      "  30000/ 200000: 2.0052\n",
      "  40000/ 200000: 2.4177\n",
      "  50000/ 200000: 1.7600\n",
      "  60000/ 200000: 2.2081\n",
      "  70000/ 200000: 1.9401\n",
      "  80000/ 200000: 2.0705\n",
      "  90000/ 200000: 1.7012\n",
      " 100000/ 200000: 2.0771\n",
      " 110000/ 200000: 1.8007\n",
      " 120000/ 200000: 1.8490\n",
      " 130000/ 200000: 2.2164\n",
      " 140000/ 200000: 2.2028\n",
      " 150000/ 200000: 1.9759\n",
      " 160000/ 200000: 2.0310\n",
      " 170000/ 200000: 2.0632\n",
      " 180000/ 200000: 2.1592\n",
      " 190000/ 200000: 1.8037\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "# INIT\n",
    "n_embd = 10\n",
    "n_hidden = 200\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "# Batchnorm paramerers\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size\n",
    "lossi = []\n",
    "\n",
    "\n",
    "# # use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        # minibatch construct\n",
    "        ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "        Xb, Yb = Xtr[ix], Ytr[ix] # batch X, Y\n",
    "    \n",
    "        # forward pass\n",
    "        emb = C[Xb]\n",
    "        embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "        # Linear Layer\n",
    "        hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "        # BatchNorm layer\n",
    "        bnmean = hprebn.mean(0, keepdim=True)\n",
    "        bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "        bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "        bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "        hpreact = bngain * bnraw + bnbias\n",
    "        # Non-linearity\n",
    "        h = torch.tanh(hpreact)\n",
    "        logits = h @ W2 + b2\n",
    "        loss = F.cross_entropy(logits, Yb)\n",
    "    \n",
    "        # Backward pass\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        #loss.backward() # this is auto, we are doing manual below\n",
    "        #---------------------------\n",
    "        dlogits = F.softmax(logits, 1)\n",
    "        dlogits[range(n), Yb] -= 1\n",
    "        dlogits /= n\n",
    "        # 2nd layer backprop\n",
    "        dh = dlogits @ W2.T\n",
    "        dW2 = h.T @ dlogits\n",
    "        db2 = dlogits.sum(0)\n",
    "        # Tanh\n",
    "        dhpreact = (1.0 - h**2) * dh\n",
    "        # batchnorm backprop\n",
    "        dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "        dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "        dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "        # 1st layer\n",
    "        dembcat = dhprebn @ W1.T\n",
    "        dW1 = embcat.T @ dhprebn\n",
    "        db1 = dhprebn.sum(0)\n",
    "        #embedding\n",
    "        demb = dembcat.view(emb.shape)\n",
    "        dC = torch.zeros_like(C)\n",
    "        for k in range(Xb.shape[0]):\n",
    "            for j in range(Xb.shape[1]):\n",
    "                ix = Xb[k, j]\n",
    "                dC[ix] += demb[k, j]\n",
    "    \n",
    "        grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "        # --------------\n",
    "    \n",
    "        # update\n",
    "        lr = 0.1 if i < 100000 else 0.01\n",
    "        for p, grad in zip(parameters, grads):\n",
    "            # p.data += -lr * p.grad # old way when we use pytorch .backward()\n",
    "            p.data += -lr * grad\n",
    "    \n",
    "        # track status\n",
    "        if i % 10000 == 0:\n",
    "            print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "        lossi.append(loss.log10().item())\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "42a9c549-e839-40fd-83df-b0987d7f46e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "89d4d141-2ddd-493d-a4fa-be90ad5f8c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1.9411180019378662\n",
      "val 2.0459790229797363\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "41cc5f68-9327-43ee-bd4c-21c1fae78140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carmah.\n",
      "amelle.\n",
      "khirmil.\n",
      "rehiyah.\n",
      "cassie.\n",
      "rahnen.\n",
      "deniyat.\n",
      "kaeli.\n",
      "nellara.\n",
      "chaiir.\n",
      "kaleigh.\n",
      "hamanii.\n",
      "dessan.\n",
      "sulina.\n",
      "livabiul.\n",
      "jerogie.\n",
      "ryxia.\n",
      "kaelynn.\n",
      "abee.\n",
      "deci.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0edf87-1ad6-47b6-baf6-8c9f72ab2584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e52c8-a0c9-48e9-b63d-d9c90f917513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d9321-46e4-4e6c-b9be-3d451ab0cd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c1eab-ba85-4eca-ac86-0e3ce33c49ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c3044-2183-49f9-b7b9-51a5e740ae32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5fbcb-fca4-4d4a-a51d-c10b9c1a4886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64883ca-784f-4a9d-b1b5-5babf89f3e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c80cdc-eaf3-482b-80ea-fefd1d9b5f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf710df7-ac85-4ce9-9599-b829b3c3429e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477620d4-b231-406e-a39a-9362246b76d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaceabe-f40b-46e5-95d0-e2275f86e344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
